#!/usr/bin/env python3
"""Build a per-node wind-resource summary table with schema backlinks.

The command fuses empirical ANN metrics, censored Weibull diagnostics, and
Kaplan-Meier fallback statistics into a tidy, per-node dataset. It exports
both CSV and Parquet representations and records metadata linking every
output column to the definitions documented in ``docs/sar_range_final_schema.md``.

All heavy aggregations execute inside ``duckdb/duckdb:latest`` to honour the
project requirement of using the containerised DuckDB image for GeoParquet
queries. No third-party Python dependencies are required.
"""

from __future__ import annotations

import argparse
import json
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, Iterable, Mapping, Sequence

import subprocess
import sys

REPO_ROOT = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(REPO_ROOT / "src"))

from hf_wind_resource.io import resolve_catalog_asset  # noqa: E402

DEFAULT_IMAGE = "duckdb/duckdb:latest"
DEFAULT_STAC_CONFIG = REPO_ROOT / "config" / "stac_catalogs.json"
DEFAULT_STAC_DATASET = "sar_range_final_pivots_joined"
DEFAULT_OUTPUT_DIR = REPO_ROOT / "artifacts" / "power_estimates" / "node_summary"
DEFAULT_POWER_SUMMARY = REPO_ROOT / "artifacts" / "power_estimates" / "power_estimates_summary.csv"
DEFAULT_EMPIRICAL_SUMMARY = REPO_ROOT / "artifacts" / "empirical_metrics" / "per_node_summary.csv"
DEFAULT_KAPLAN_MEIER_SUMMARY = (
    REPO_ROOT / "artifacts" / "nonparametric_distributions" / "kaplan_meier_summary.csv"
)


class DuckDBError(RuntimeError):
    """Raised when DuckDB returns a non-zero exit status."""


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument(
        "--stac-config",
        type=Path,
        default=DEFAULT_STAC_CONFIG,
        help="Path to the STAC catalog index JSON resolving ANN inference assets.",
    )
    parser.add_argument(
        "--stac-dataset",
        default=DEFAULT_STAC_DATASET,
        help="Dataset key within the STAC index identifying the ANN GeoParquet asset.",
    )
    parser.add_argument(
        "--dataset",
        type=Path,
        default=None,
        help="Direct path to the ANN GeoParquet asset (overrides STAC resolution).",
    )
    parser.add_argument(
        "--power-summary",
        type=Path,
        default=DEFAULT_POWER_SUMMARY,
        help="CSV generated by scripts/generate_power_estimates.py (per-node power metrics).",
    )
    parser.add_argument(
        "--empirical-summary",
        type=Path,
        default=DEFAULT_EMPIRICAL_SUMMARY,
        help="CSV emitted by scripts/generate_empirical_metrics.py (label ratios, bias flags, moments).",
    )
    parser.add_argument(
        "--kaplan-meier-summary",
        type=Path,
        default=DEFAULT_KAPLAN_MEIER_SUMMARY,
        help="CSV exported by scripts/generate_nonparametric_distributions.py (Kaplan-Meier metrics).",
    )
    parser.add_argument(
        "--output-dir",
        type=Path,
        default=DEFAULT_OUTPUT_DIR,
        help="Directory where CSV, Parquet, and metadata JSON will be stored.",
    )
    parser.add_argument(
        "--image",
        default=DEFAULT_IMAGE,
        help="Docker image used to run DuckDB (defaults to duckdb/duckdb:latest).",
    )
    parser.add_argument(
        "--engine",
        choices=("docker", "python"),
        default="docker",
        help="Execution engine for DuckDB. Use 'python' when the docker CLI is unavailable but the duckdb package is installed.",
    )
    parser.add_argument(
        "--overwrite",
        action="store_true",
        help="Allow replacing existing outputs in --output-dir.",
    )
    return parser.parse_args()


def ensure_exists(path: Path, *, label: str) -> None:
    if not path.exists():
        raise FileNotFoundError(f"Missing {label}: {path}")


def repo_relative(path: Path) -> str:
    try:
        return str(path.resolve().relative_to(REPO_ROOT))
    except ValueError:
        return str(path.resolve())


def run_duckdb_sql(sql: str, *, engine: str, image: str) -> None:
    if engine == "docker":
        command = [
            "docker",
            "run",
            "--rm",
            "-v",
            f"{REPO_ROOT}:/workspace",
            "-w",
            "/workspace",
            image,
            "duckdb",
            "-cmd",
            sql.replace("\n", " "),
        ]
        result = subprocess.run(command, capture_output=True, text=True, check=False)
        if result.returncode != 0:
            raise DuckDBError(f"DuckDB (docker) failed with code {result.returncode}:\n{result.stderr.strip()}")
        return

    try:
        import duckdb  # type: ignore
    except ImportError as exc:
        raise DuckDBError(
            "DuckDB Python module not available. Install `duckdb` or rerun with --engine docker."
        ) from exc

    normalized = sql.replace("\n", " ")
    with duckdb.connect(database=":memory:") as conn:
        conn.execute(normalized)


def build_summary_sql(
    *,
    dataset_path: Path,
    power_path: Path,
    empirical_path: Path,
    km_path: Path,
    csv_output: Path,
    parquet_output: Path,
) -> str:
    dataset = repo_relative(dataset_path).replace("'", "''")
    power = repo_relative(power_path).replace("'", "''")
    empirical = repo_relative(empirical_path).replace("'", "''")
    km = repo_relative(km_path).replace("'", "''")
    csv_out = repo_relative(csv_output).replace("'", "''")
    parquet_out = repo_relative(parquet_output).replace("'", "''")

    select_statement = f"""
    WITH power AS (
        SELECT * FROM read_csv_auto('{power}', header=True, union_by_name=True)
    ),
    empirical AS (
        SELECT * FROM read_csv_auto('{empirical}', header=True, union_by_name=True)
    ),
    km AS (
        SELECT * FROM read_csv_auto('{km}', header=True, union_by_name=True)
    ),
    node_ids AS (
        SELECT DISTINCT node_id FROM power
        UNION
        SELECT DISTINCT node_id FROM empirical
        UNION
        SELECT DISTINCT node_id FROM km
    ),
    geometries AS (
        SELECT node_id, geometry
        FROM (
            SELECT
                node_id,
                geometry,
                ROW_NUMBER() OVER (PARTITION BY node_id ORDER BY node_id) AS rn
            FROM read_parquet('{dataset}')
        )
        WHERE rn = 1
    )
    SELECT
        n.node_id,
        g.geometry,
        power.method AS selected_method,
        CASE
            WHEN power.method = 'weibull' AND km.km_p50 IS NOT NULL THEN 'kaplan_meier'
            WHEN power.method = 'kaplan_meier' AND (power.weibull_reliable IS TRUE OR power.weibull_success IS TRUE)
                 THEN 'weibull'
            ELSE NULL
        END AS alternate_method,
        CASE
            WHEN power.method = 'weibull' THEN (power.weibull_reliable IS TRUE) AND (empirical.any_bias IS FALSE OR empirical.any_bias IS NULL)
            WHEN power.method = 'kaplan_meier' THEN (empirical.any_bias IS FALSE OR empirical.any_bias IS NULL)
            ELSE NULL
        END AS reliable_estimate,
        power.air_density,
        power.power_density_w_m2,
        power.capacity_factor,
        power.turbine_mean_power_kw,
        power.power_density_method,
        power.power_density_notes,
        power.power_curve_name,
        power.power_curve_notes,
        power.weibull_success,
        power.weibull_reliable,
        power.weibull_shape,
        power.weibull_scale,
        power.weibull_log_likelihood,
        power.weibull_in_weight,
        power.weibull_left_weight,
        power.weibull_right_weight,
        power.weibull_iterations,
        power.weibull_gradient_norm,
        power.weibull_last_step_size,
        power.weibull_message,
        power.kaplan_meier_tail_probability,
        power.kaplan_meier_selection_reasons,
        power.height_method,
        power.height_source_m,
        power.height_target_m,
        power.height_speed_scale,
        power.height_power_law_alpha,
        power.height_roughness_length_m,
        empirical.total_observations,
        empirical.taxonomy_observations,
        empirical.valid_count,
        empirical.mean_speed AS mean_speed_m_s,
        empirical.std_speed AS std_speed_m_s,
        empirical.min_speed AS min_speed_m_s,
        empirical.max_speed AS max_speed_m_s,
        empirical.p50 AS speed_p50_m_s,
        empirical.p90 AS speed_p90_m_s,
        empirical.p99 AS speed_p99_m_s,
        (empirical.max_speed - empirical.min_speed) AS in_range_span_m_s,
        (empirical.p90 - empirical.p50) AS p90_minus_p50_m_s,
        empirical.in_count,
        empirical.in_ratio,
        empirical.below_count,
        empirical.below_ratio,
        empirical.above_count,
        empirical.above_ratio,
        empirical.uncertain_count,
        empirical.uncertain_ratio,
        empirical.censored_ratio,
        empirical.any_bias,
        empirical.bias_notes,
        empirical.censoring_bias,
        empirical.coverage_bias,
        empirical.sample_bias,
        empirical.low_coverage,
        empirical.coverage_band,
        empirical.continuity_band,
        km.left_mass_ratio AS km_left_mass_ratio,
        km.right_tail_probability AS km_right_tail_probability,
        km.km_p50 AS km_p50_m_s,
        km.km_p90 AS km_p90_m_s,
        km.km_p99 AS km_p99_m_s,
        (km.km_p90 - km.km_p50) AS km_interval_width_m_s,
        km.reasons AS km_activation_reasons
    FROM node_ids n
    LEFT JOIN power ON power.node_id = n.node_id
    LEFT JOIN empirical ON empirical.node_id = n.node_id
    LEFT JOIN km ON km.node_id = n.node_id
    LEFT JOIN geometries g ON g.node_id = n.node_id
    ORDER BY n.node_id
    """

    return f"""
    COPY ({select_statement}) TO '{csv_out}' WITH (HEADER, DELIMITER ',');
    COPY ({select_statement}) TO '{parquet_out}' (FORMAT PARQUET);
    """


COLUMN_METADATA: Dict[str, Mapping[str, object]] = {
    "node_id": {
        "description": "Spatial grid node identifier shared across SAR range-aware products.",
        "doc_reference": "docs/sar_range_final_schema.md#core-columns",
        "source_fields": ["node_id"],
    },
    "geometry": {
        "description": "Node footprint geometry encoded as WKB (CRS84).",
        "doc_reference": "docs/sar_range_final_schema.md#core-columns",
        "source_fields": ["geometry"],
    },
    "selected_method": {
        "description": "Estimator used for the published power density (weibull or kaplan_meier).",
        "doc_reference": "docs/sar_range_final_schema.md#range-classes-and-censoring-thresholds",
        "source_fields": ["pred_range_label", "prob_range_in", "prob_range_below", "prob_range_above"],
    },
    "alternate_method": {
        "description": "Secondary estimator available for bias diagnostics (opposite of selected_method when applicable).",
        "doc_reference": "docs/sar_range_final_schema.md#range-classes-and-censoring-thresholds",
        "source_fields": ["pred_range_label", "prob_range_in", "prob_range_below", "prob_range_above"],
    },
    "reliable_estimate": {
        "description": "Boolean flag marking nodes whose primary estimator passed reliability checks and bias guards.",
        "doc_reference": "docs/sar_range_final_schema.md#range-classes-and-censoring-thresholds",
        "source_fields": ["range_flag", "range_flag_confident"],
    },
    "air_density": {
        "description": "Air-density assumption applied when computing turbine power (kg/m^3).",
        "doc_reference": "docs/sar_range_final_schema.md#predicted-wind-outputs",
        "source_fields": ["pred_wind_speed"],
    },
    "power_density_w_m2": {
        "description": "Wind power density at hub height derived from the selected estimator (W/m^2).",
        "doc_reference": "docs/sar_range_final_schema.md#predicted-wind-outputs",
        "source_fields": ["pred_wind_speed"],
    },
    "capacity_factor": {
        "description": "Expected capacity factor for the reference turbine (0-1 range).",
        "doc_reference": "docs/sar_range_final_schema.md#predicted-wind-outputs",
        "source_fields": ["pred_wind_speed"],
    },
    "turbine_mean_power_kw": {
        "description": "Mean power output of the reference turbine under the selected estimator (kW).",
        "doc_reference": "docs/sar_range_final_schema.md#predicted-wind-outputs",
        "source_fields": ["pred_wind_speed"],
    },
    "power_density_method": {
        "description": "Internal label describing how power density was computed (e.g., weibull, kaplan_meier).",
        "doc_reference": "docs/sar_range_final_schema.md#range-classes-and-censoring-thresholds",
        "source_fields": ["pred_range_label"],
    },
    "power_density_notes": {
        "description": "Free-form notes capturing the assumptions made during power density computation.",
        "doc_reference": "docs/sar_range_final_schema.md#range-classes-and-censoring-thresholds",
        "source_fields": ["pred_range_label"],
    },
    "power_curve_name": {
        "description": "Human-readable identifier of the reference turbine power curve.",
        "doc_reference": "docs/sar_range_final_schema.md#predicted-wind-outputs",
        "source_fields": ["pred_wind_speed"],
    },
    "power_curve_notes": {
        "description": "Narrative summary of the power-curve assumptions (cut-in/out, rated speed).",
        "doc_reference": "docs/sar_range_final_schema.md#predicted-wind-outputs",
        "source_fields": ["pred_wind_speed"],
    },
    "weibull_success": {
        "description": "Flag describing whether the censored Weibull optimisation converged successfully.",
        "doc_reference": "docs/sar_range_final_schema.md#predicted-wind-outputs",
        "source_fields": ["pred_wind_speed"],
    },
    "weibull_reliable": {
        "description": "Flag indicating if the Weibull fit satisfied reliability thresholds (sample size, censoring).",
        "doc_reference": "docs/sar_range_final_schema.md#range-classes-and-censoring-thresholds",
        "source_fields": ["range_flag", "prob_range_in"],
    },
    "weibull_shape": {
        "description": "Shape parameter k of the censored Weibull fit.",
        "doc_reference": "docs/sar_range_final_schema.md#predicted-wind-outputs",
        "source_fields": ["pred_wind_speed"],
    },
    "weibull_scale": {
        "description": "Scale parameter lambda of the censored Weibull fit.",
        "doc_reference": "docs/sar_range_final_schema.md#predicted-wind-outputs",
        "source_fields": ["pred_wind_speed"],
    },
    "weibull_log_likelihood": {
        "description": "Log-likelihood value reached by the censored Weibull optimisation.",
        "doc_reference": "docs/sar_range_final_schema.md#predicted-wind-outputs",
        "source_fields": ["pred_wind_speed"],
    },
    "weibull_in_weight": {
        "description": "Total weight of in-range samples feeding the Weibull fit.",
        "doc_reference": "docs/sar_range_final_schema.md#range-classes-and-censoring-thresholds",
        "source_fields": ["prob_range_in"],
    },
    "weibull_left_weight": {
        "description": "Total weight of left-censored samples used during the Weibull fit.",
        "doc_reference": "docs/sar_range_final_schema.md#range-classes-and-censoring-thresholds",
        "source_fields": ["prob_range_below"],
    },
    "weibull_right_weight": {
        "description": "Total weight of right-censored samples used during the Weibull fit.",
        "doc_reference": "docs/sar_range_final_schema.md#range-classes-and-censoring-thresholds",
        "source_fields": ["prob_range_above"],
    },
    "weibull_iterations": {
        "description": "Number of optimisation iterations executed by the Weibull solver.",
        "doc_reference": "docs/sar_range_final_schema.md#predicted-wind-outputs",
        "source_fields": ["pred_wind_speed"],
    },
    "weibull_gradient_norm": {
        "description": "Gradient norm reported at the last Weibull iteration (diagnostic).",
        "doc_reference": "docs/sar_range_final_schema.md#predicted-wind-outputs",
        "source_fields": ["pred_wind_speed"],
    },
    "weibull_last_step_size": {
        "description": "Last step size used by the Weibull optimiser (diagnostic).",
        "doc_reference": "docs/sar_range_final_schema.md#predicted-wind-outputs",
        "source_fields": ["pred_wind_speed"],
    },
    "weibull_message": {
        "description": "Solver message describing the termination state of the Weibull fit.",
        "doc_reference": "docs/sar_range_final_schema.md#predicted-wind-outputs",
        "source_fields": ["pred_wind_speed"],
    },
    "weibull_aic": {
        "description": "Akaike Information Criterion for the censored Weibull candidate.",
        "doc_reference": "docs/power_estimation_methodology.md",
        "source_fields": ["pred_wind_speed"],
    },
    "weibull_bic": {
        "description": "Bayesian Information Criterion for the censored Weibull candidate.",
        "doc_reference": "docs/power_estimation_methodology.md",
        "source_fields": ["pred_wind_speed"],
    },
    "weibull_ks_statistic": {
        "description": "Weighted Kolmogorovâ€“Smirnov statistic comparing Weibull CDF vs. in-range empirical CDF.",
        "doc_reference": "docs/power_estimation_methodology.md",
        "source_fields": ["pred_wind_speed"],
    },
    "weibull_ks_pvalue": {
        "description": "Approximate p-value derived from the Weibull KS statistic.",
        "doc_reference": "docs/power_estimation_methodology.md",
        "source_fields": ["pred_wind_speed"],
    },
    "weibull_parametric_success": {
        "description": "Boolean flag marking whether the Weibull candidate was usable for comparison.",
        "doc_reference": "docs/power_estimation_methodology.md",
        "source_fields": ["pred_wind_speed"],
    },
    "weibull_parametric_notes": {
        "description": "Notes emitted during the Weibull candidate evaluation stage.",
        "doc_reference": "docs/power_estimation_methodology.md",
        "source_fields": ["pred_wind_speed"],
    },
    "lognormal_log_likelihood": {
        "description": "Censored log-likelihood obtained from the log-normal candidate.",
        "doc_reference": "docs/power_estimation_methodology.md",
        "source_fields": ["pred_wind_speed"],
    },
    "lognormal_aic": {
        "description": "AIC derived from the log-normal log-likelihood.",
        "doc_reference": "docs/power_estimation_methodology.md",
        "source_fields": ["pred_wind_speed"],
    },
    "lognormal_bic": {
        "description": "BIC derived from the log-normal log-likelihood.",
        "doc_reference": "docs/power_estimation_methodology.md",
        "source_fields": ["pred_wind_speed"],
    },
    "lognormal_ks_statistic": {
        "description": "Weighted KS statistic comparing the log-normal CDF vs. the empirical CDF.",
        "doc_reference": "docs/power_estimation_methodology.md",
        "source_fields": ["pred_wind_speed"],
    },
    "lognormal_ks_pvalue": {
        "description": "Approximate p-value assigned to the log-normal KS statistic.",
        "doc_reference": "docs/power_estimation_methodology.md",
        "source_fields": ["pred_wind_speed"],
    },
    "lognormal_parametric_success": {
        "description": "Boolean indicator for the validity of the log-normal candidate.",
        "doc_reference": "docs/power_estimation_methodology.md",
        "source_fields": ["pred_wind_speed"],
    },
    "lognormal_parametric_notes": {
        "description": "Notes detailing how the log-normal candidate was handled (e.g., insufficient support).",
        "doc_reference": "docs/power_estimation_methodology.md",
        "source_fields": ["pred_wind_speed"],
    },
    "lognormal_mu": {
        "description": "Mean (mu) of the underlying normal distribution in the log-normal candidate.",
        "doc_reference": "docs/power_estimation_methodology.md",
        "source_fields": ["pred_wind_speed"],
    },
    "lognormal_sigma": {
        "description": "Standard deviation (sigma) of the underlying normal distribution in the log-normal candidate.",
        "doc_reference": "docs/power_estimation_methodology.md",
        "source_fields": ["pred_wind_speed"],
    },
    "gamma_log_likelihood": {
        "description": "Censored log-likelihood obtained from the gamma candidate.",
        "doc_reference": "docs/power_estimation_methodology.md",
        "source_fields": ["pred_wind_speed"],
    },
    "gamma_aic": {
        "description": "AIC derived from the gamma log-likelihood.",
        "doc_reference": "docs/power_estimation_methodology.md",
        "source_fields": ["pred_wind_speed"],
    },
    "gamma_bic": {
        "description": "BIC derived from the gamma log-likelihood.",
        "doc_reference": "docs/power_estimation_methodology.md",
        "source_fields": ["pred_wind_speed"],
    },
    "gamma_ks_statistic": {
        "description": "Weighted KS statistic comparing the gamma CDF vs. the empirical CDF.",
        "doc_reference": "docs/power_estimation_methodology.md",
        "source_fields": ["pred_wind_speed"],
    },
    "gamma_ks_pvalue": {
        "description": "Approximate p-value assigned to the gamma KS statistic.",
        "doc_reference": "docs/power_estimation_methodology.md",
        "source_fields": ["pred_wind_speed"],
    },
    "gamma_parametric_success": {
        "description": "Boolean indicator for the validity of the gamma candidate.",
        "doc_reference": "docs/power_estimation_methodology.md",
        "source_fields": ["pred_wind_speed"],
    },
    "gamma_parametric_notes": {
        "description": "Notes emitted while evaluating the gamma candidate (e.g., SciPy availability).",
        "doc_reference": "docs/power_estimation_methodology.md",
        "source_fields": ["pred_wind_speed"],
    },
    "gamma_shape": {
        "description": "Shape parameter estimated for the gamma candidate.",
        "doc_reference": "docs/power_estimation_methodology.md",
        "source_fields": ["pred_wind_speed"],
    },
    "gamma_scale": {
        "description": "Scale parameter estimated for the gamma candidate.",
        "doc_reference": "docs/power_estimation_methodology.md",
        "source_fields": ["pred_wind_speed"],
    },
    "parametric_selection_metric": {
        "description": "Information criterion (AIC/BIC) used to select the preferred parametric model.",
        "doc_reference": "docs/power_estimation_methodology.md",
        "source_fields": ["pred_wind_speed"],
    },
    "parametric_preferred_model": {
        "description": "Name of the parametric model (weibull/lognormal/gamma) preferred for the node.",
        "doc_reference": "docs/power_estimation_methodology.md",
        "source_fields": ["pred_wind_speed"],
    },
    "parametric_preferred_metric_value": {
        "description": "Metric value delivered by the preferred parametric model.",
        "doc_reference": "docs/power_estimation_methodology.md",
        "source_fields": ["pred_wind_speed"],
    },
    "parametric_notes": {
        "description": "Notes summarising the comparison across parametric candidates.",
        "doc_reference": "docs/power_estimation_methodology.md",
        "source_fields": ["pred_wind_speed"],
    },
    "kaplan_meier_tail_probability": {
        "description": "Right-tail probability mass captured by the Kaplan-Meier estimator.",
        "doc_reference": "docs/sar_range_final_schema.md#range-classes-and-censoring-thresholds",
        "source_fields": ["prob_range_above"],
    },
    "kaplan_meier_selection_reasons": {
        "description": "Diagnostic notes explaining why the Kaplan-Meier fallback was activated.",
        "doc_reference": "docs/sar_range_final_schema.md#range-classes-and-censoring-thresholds",
        "source_fields": ["range_flag", "prob_range_below", "prob_range_in", "prob_range_above"],
    },
    "height_method": {
        "description": "Vertical extrapolation approach applied to ANN wind speeds.",
        "doc_reference": "docs/sar_range_final_schema.md#predicted-wind-outputs",
        "source_fields": ["pred_wind_speed"],
    },
    "height_source_m": {
        "description": "Source height of the ANN-derived wind speeds (m).",
        "doc_reference": "docs/sar_range_final_schema.md#predicted-wind-outputs",
        "source_fields": ["pred_wind_speed"],
    },
    "height_target_m": {
        "description": "Target hub height used when scaling wind speeds (m).",
        "doc_reference": "docs/sar_range_final_schema.md#predicted-wind-outputs",
        "source_fields": ["pred_wind_speed"],
    },
    "height_speed_scale": {
        "description": "Multiplicative factor applied to wind speeds during vertical extrapolation.",
        "doc_reference": "docs/sar_range_final_schema.md#predicted-wind-outputs",
        "source_fields": ["pred_wind_speed"],
    },
    "height_power_law_alpha": {
        "description": "Exponent of the power-law vertical extrapolation (if applicable).",
        "doc_reference": "docs/sar_range_final_schema.md#predicted-wind-outputs",
        "source_fields": ["pred_wind_speed"],
    },
    "height_roughness_length_m": {
        "description": "Surface roughness length assumed during log-law extrapolation (m).",
        "doc_reference": "docs/sar_range_final_schema.md#predicted-wind-outputs",
        "source_fields": ["pred_wind_speed"],
    },
    "total_observations": {
        "description": "Total number of ANN records contributing to the node.",
        "doc_reference": "docs/sar_range_final_schema.md#node-sampling-density",
        "source_fields": ["pred_range_label"],
    },
    "taxonomy_observations": {
        "description": "Observation count registered in the node taxonomy metadata.",
        "doc_reference": "docs/sar_range_final_schema.md#node-sampling-density",
        "source_fields": ["node_id"],
    },
    "valid_count": {
        "description": "Count of ANN samples classified inside the regression range.",
        "doc_reference": "docs/sar_range_final_schema.md#range-classes-and-censoring-thresholds",
        "source_fields": ["pred_range_label"],
    },
    "mean_speed_m_s": {
        "description": "Mean ANN wind speed restricted to in-range samples (m/s).",
        "doc_reference": "docs/sar_range_final_schema.md#predicted-wind-outputs",
        "source_fields": ["pred_wind_speed"],
    },
    "std_speed_m_s": {
        "description": "Sample standard deviation of in-range ANN wind speeds (m/s).",
        "doc_reference": "docs/sar_range_final_schema.md#predicted-wind-outputs",
        "source_fields": ["pred_wind_speed"],
    },
    "min_speed_m_s": {
        "description": "Minimum in-range ANN wind speed (m/s).",
        "doc_reference": "docs/sar_range_final_schema.md#predicted-wind-outputs",
        "source_fields": ["pred_wind_speed"],
    },
    "max_speed_m_s": {
        "description": "Maximum in-range ANN wind speed (m/s).",
        "doc_reference": "docs/sar_range_final_schema.md#predicted-wind-outputs",
        "source_fields": ["pred_wind_speed"],
    },
    "speed_p50_m_s": {
        "description": "Median (P50) of in-range ANN wind speeds (m/s).",
        "doc_reference": "docs/sar_range_final_schema.md#predicted-wind-outputs",
        "source_fields": ["pred_wind_speed"],
    },
    "speed_p90_m_s": {
        "description": "90th percentile of in-range ANN wind speeds (m/s).",
        "doc_reference": "docs/sar_range_final_schema.md#predicted-wind-outputs",
        "source_fields": ["pred_wind_speed"],
    },
    "speed_p99_m_s": {
        "description": "99th percentile of in-range ANN wind speeds (m/s).",
        "doc_reference": "docs/sar_range_final_schema.md#predicted-wind-outputs",
        "source_fields": ["pred_wind_speed"],
    },
    "in_range_span_m_s": {
        "description": "Range width between max and min in-range ANN wind speeds (m/s).",
        "doc_reference": "docs/sar_range_final_schema.md#predicted-wind-outputs",
        "source_fields": ["pred_wind_speed"],
    },
    "p90_minus_p50_m_s": {
        "description": "Difference between P90 and P50 in-range speeds (m/s).",
        "doc_reference": "docs/sar_range_final_schema.md#predicted-wind-outputs",
        "source_fields": ["pred_wind_speed"],
    },
    "in_count": {
        "description": "Raw count of samples classified within the regression range.",
        "doc_reference": "docs/sar_range_final_schema.md#range-classes-and-censoring-thresholds",
        "source_fields": ["pred_range_label"],
    },
    "in_ratio": {
        "description": "Share of samples labelled within the regression range.",
        "doc_reference": "docs/sar_range_final_schema.md#range-classes-and-censoring-thresholds",
        "source_fields": ["pred_range_label"],
    },
    "below_count": {
        "description": "Raw count of samples classified below the regression range.",
        "doc_reference": "docs/sar_range_final_schema.md#range-classes-and-censoring-thresholds",
        "source_fields": ["pred_range_label"],
    },
    "below_ratio": {
        "description": "Share of samples classified below the regression range.",
        "doc_reference": "docs/sar_range_final_schema.md#range-classes-and-censoring-thresholds",
        "source_fields": ["pred_range_label"],
    },
    "above_count": {
        "description": "Raw count of samples classified above the regression range.",
        "doc_reference": "docs/sar_range_final_schema.md#range-classes-and-censoring-thresholds",
        "source_fields": ["pred_range_label"],
    },
    "above_ratio": {
        "description": "Share of samples classified above the regression range.",
        "doc_reference": "docs/sar_range_final_schema.md#range-classes-and-censoring-thresholds",
        "source_fields": ["pred_range_label"],
    },
    "uncertain_count": {
        "description": "Raw count of samples with low classifier confidence.",
        "doc_reference": "docs/sar_range_final_schema.md#range-classes-and-censoring-thresholds",
        "source_fields": ["range_flag", "range_flag_confident"],
    },
    "uncertain_ratio": {
        "description": "Share of samples with low classifier confidence.",
        "doc_reference": "docs/sar_range_final_schema.md#range-classes-and-censoring-thresholds",
        "source_fields": ["range_flag", "range_flag_confident"],
    },
    "censored_ratio": {
        "description": "Combined share of left and right censored samples.",
        "doc_reference": "docs/sar_range_final_schema.md#range-classes-and-censoring-thresholds",
        "source_fields": ["pred_range_label"],
    },
    "any_bias": {
        "description": "Composite bias flag covering censoring, coverage, and sample-size diagnostics.",
        "doc_reference": "docs/sar_range_final_schema.md#node-sampling-density",
        "source_fields": ["node_id"],
    },
    "bias_notes": {
        "description": "Human-readable summary of the bias diagnostics triggered for the node.",
        "doc_reference": "docs/sar_range_final_schema.md#node-sampling-density",
        "source_fields": ["node_id"],
    },
    "censoring_bias": {
        "description": "Flag raised when censoring ratios exceed configured thresholds.",
        "doc_reference": "docs/sar_range_final_schema.md#range-classes-and-censoring-thresholds",
        "source_fields": ["pred_range_label"],
    },
    "coverage_bias": {
        "description": "Flag raised when taxonomy coverage bands indicate sparse sampling.",
        "doc_reference": "docs/sar_range_final_schema.md#node-sampling-density",
        "source_fields": ["node_id"],
    },
    "sample_bias": {
        "description": "Flag raised when the number of in-range samples is below the minimum threshold.",
        "doc_reference": "docs/sar_range_final_schema.md#node-sampling-density",
        "source_fields": ["node_id"],
    },
    "low_coverage": {
        "description": "Boolean indicator derived from taxonomy metadata highlighting low coverage nodes.",
        "doc_reference": "docs/sar_range_final_schema.md#node-sampling-density",
        "source_fields": ["node_id"],
    },
    "coverage_band": {
        "description": "Coverage band assigned to the node by the taxonomy (dense, moderate, sparse).",
        "doc_reference": "docs/sar_range_final_schema.md#node-sampling-density",
        "source_fields": ["node_id"],
    },
    "continuity_band": {
        "description": "Continuity band assigned during taxonomy QA (continuous, long_gaps, etc.).",
        "doc_reference": "docs/sar_range_final_schema.md#node-sampling-density",
        "source_fields": ["node_id"],
    },
    "km_left_mass_ratio": {
        "description": "Left-censored probability mass estimated by the Kaplan-Meier survival function.",
        "doc_reference": "docs/sar_range_final_schema.md#range-classes-and-censoring-thresholds",
        "source_fields": ["prob_range_below"],
    },
    "km_right_tail_probability": {
        "description": "Residual right-tail probability mass estimated by Kaplan-Meier.",
        "doc_reference": "docs/sar_range_final_schema.md#range-classes-and-censoring-thresholds",
        "source_fields": ["prob_range_above"],
    },
    "km_p50_m_s": {
        "description": "Kaplan-Meier median wind speed treating censored samples explicitly (m/s).",
        "doc_reference": "docs/sar_range_final_schema.md#predicted-wind-outputs",
        "source_fields": ["pred_wind_speed"],
    },
    "km_p90_m_s": {
        "description": "Kaplan-Meier 90th percentile wind speed (m/s).",
        "doc_reference": "docs/sar_range_final_schema.md#predicted-wind-outputs",
        "source_fields": ["pred_wind_speed"],
    },
    "km_p99_m_s": {
        "description": "Kaplan-Meier 99th percentile wind speed (m/s).",
        "doc_reference": "docs/sar_range_final_schema.md#predicted-wind-outputs",
        "source_fields": ["pred_wind_speed"],
    },
    "km_interval_width_m_s": {
        "description": "Width between Kaplan-Meier P90 and P50, highlighting distribution spread under censoring (m/s).",
        "doc_reference": "docs/sar_range_final_schema.md#predicted-wind-outputs",
        "source_fields": ["pred_wind_speed"],
    },
    "km_activation_reasons": {
        "description": "Reasons why the Kaplan-Meier estimator was computed or selected (text).",
        "doc_reference": "docs/sar_range_final_schema.md#range-classes-and-censoring-thresholds",
        "source_fields": ["range_flag", "prob_range_below", "prob_range_in", "prob_range_above"],
    },
}


def write_metadata(
    output_dir: Path,
    *,
    inputs: Mapping[str, str],
) -> None:
    metadata_path = output_dir / "node_summary_metadata.json"
    payload = {
        "generated_at": datetime.now(timezone.utc).isoformat(),
        "inputs": inputs,
        "columns": [
            {"name": name, **metadata}
            for name, metadata in COLUMN_METADATA.items()
        ],
    }
    metadata_path.write_text(json.dumps(payload, indent=2, sort_keys=True), encoding="utf-8")


def main() -> None:
    args = parse_args()

    output_dir = args.output_dir if args.output_dir.is_absolute() else (REPO_ROOT / args.output_dir)
    if output_dir.exists():
        if not args.overwrite:
            raise FileExistsError(f"{output_dir} already exists; pass --overwrite to replace it.")
    else:
        output_dir.mkdir(parents=True, exist_ok=True)

    ensure_exists(args.power_summary, label="power summary CSV")
    ensure_exists(args.empirical_summary, label="empirical summary CSV")
    ensure_exists(args.kaplan_meier_summary, label="Kaplan-Meier summary CSV")
    if args.dataset is None:
        ensure_exists(args.stac_config, label="STAC catalog configuration")
        resolved = resolve_catalog_asset(
            args.stac_dataset,
            config_path=args.stac_config,
            root=REPO_ROOT,
        )
        dataset_path = resolved.require_local_path()
    else:
        dataset_path = args.dataset if args.dataset.is_absolute() else (REPO_ROOT / args.dataset)
        ensure_exists(dataset_path, label="dataset")
    dataset_path = dataset_path.resolve()

    csv_output = output_dir / "node_summary.csv"
    parquet_output = output_dir / "node_summary.parquet"

    sql = build_summary_sql(
        dataset_path=dataset_path,
        power_path=args.power_summary,
        empirical_path=args.empirical_summary,
        km_path=args.kaplan_meier_summary,
        csv_output=csv_output,
        parquet_output=parquet_output,
    )
    run_duckdb_sql(sql, engine=args.engine, image=args.image)

    inputs = {
        "dataset": repo_relative(dataset_path),
        "power_summary": repo_relative(args.power_summary),
        "empirical_summary": repo_relative(args.empirical_summary),
        "kaplan_meier_summary": repo_relative(args.kaplan_meier_summary),
    }
    write_metadata(output_dir, inputs=inputs)


if __name__ == "__main__":
    main()
