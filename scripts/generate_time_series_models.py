#!/usr/bin/env python3
"""Fit ARIMA/SARIMA and ETS models on the monthly power time-series."""

from __future__ import annotations

import argparse
import json
from pathlib import Path
from typing import Iterable, Mapping

import pandas as pd

from hf_wind_resource.stats import (
    EtsResult,
    SarimaResult,
    TimeSeriesSegment,
    compute_acf_pacf,
    fit_ets_seasonal,
    fit_sarima_auto,
    load_time_series_config,
    prepare_monthly_series,
    split_series_by_gaps,
)


REPO_ROOT = Path(__file__).resolve().parents[1]
DEFAULT_MONTHLY_PATH = REPO_ROOT / "artifacts" / "power_estimates" / "monthly_power_timeseries.csv"
DEFAULT_OUTPUT_DIR = REPO_ROOT / "artifacts" / "power_estimates" / "time_series"


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument(
        "--input",
        type=Path,
        default=DEFAULT_MONTHLY_PATH,
        help="Path to monthly_power_timeseries.csv generated by generate_power_estimates.py.",
    )
    parser.add_argument(
        "--output",
        type=Path,
        default=DEFAULT_OUTPUT_DIR,
        help="Directory where the time-series artefacts will be stored.",
    )
    parser.add_argument(
        "--forecast-steps",
        type=int,
        default=12,
        help="Number of months to forecast ahead.",
    )
    parser.add_argument(
        "--seasonal-periods",
        type=int,
        default=12,
        help="Seasonal period for SARIMA/ETS models.",
    )
    parser.add_argument(
        "--max-gap-months",
        type=int,
        default=None,
        help="Override for the maximum consecutive months considered a small gap (filled by interpolation). Defaults to config/time_series.json.",
    )
    parser.add_argument(
        "--min-observations",
        type=int,
        default=None,
        help="Minimum observations per segmento requeridos para ajustar modelos (por defecto config/time_series.json).",
    )
    parser.add_argument(
        "--max-nodes",
        type=int,
        default=None,
        help="Limit the number of nodes processed (debug helper for lightweight runs).",
    )
    return parser.parse_args()


def _load_monthly_csv(path: Path) -> pd.DataFrame:
    resolved = path if path.is_absolute() else (REPO_ROOT / path)
    if not resolved.exists():
        raise FileNotFoundError(f"Monthly CSV not found: {resolved}")
    frame = pd.read_csv(resolved)
    required = {"node_id", "period_start", "turbine_mean_power_kw"}
    missing = required.difference(frame.columns)
    if missing:
        raise KeyError(f"Monthly CSV missing required columns: {sorted(missing)}")
    return frame


def _prepare_node_rows(frame: pd.DataFrame, node_id: str) -> Iterable[Mapping[str, object]]:
    subset = frame.loc[frame["node_id"] == node_id]
    return subset.to_dict(orient="records")


def _build_forecast_index(last_timestamp: pd.Timestamp, steps: int) -> list[str]:
    index = []
    ts = last_timestamp
    for _ in range(steps):
        ts = (ts + pd.DateOffset(months=1)).normalize()
        index.append(ts.isoformat())
    return index


def main() -> None:
    args = parse_args()
    frame = _load_monthly_csv(args.input)
    output_dir = args.output if args.output.is_absolute() else (REPO_ROOT / args.output)
    output_dir.mkdir(parents=True, exist_ok=True)
    nodes_dir = output_dir / "nodes"
    nodes_dir.mkdir(parents=True, exist_ok=True)

    config = load_time_series_config()
    max_gap = args.max_gap_months if args.max_gap_months is not None else config["max_gap_months"]
    min_observations = args.min_observations if args.min_observations is not None else config["min_segment_months"]

    summary_rows: list[dict[str, object]] = []
    nodes = sorted(frame["node_id"].unique())
    if args.max_nodes is not None:
        nodes = nodes[: args.max_nodes]

    for node_id in nodes:
        node_rows = list(_prepare_node_rows(frame, node_id))
        series = prepare_monthly_series(node_rows, value_field="turbine_mean_power_kw")
        segments = split_series_by_gaps(
            series,
            max_gap_months=max_gap,
            min_length=min_observations,
        )
        if not segments:
            continue

        segment_payloads: list[dict[str, object]] = []

        for segment_index, segment in enumerate(segments, start=1):
            seg_series = segment.series
            try:
                sarima_result: SarimaResult | None = fit_sarima_auto(
                    seg_series,
                    seasonal_periods=args.seasonal_periods,
                    max_order=1,
                    forecast_steps=args.forecast_steps,
                )
                ets_result: EtsResult | None = fit_ets_seasonal(
                    seg_series,
                    seasonal_periods=args.seasonal_periods,
                    forecast_steps=args.forecast_steps,
                )
            except ImportError as exc:  # pragma: no cover
                print(f"Skipping node {node_id}: {exc}")
                segment_payloads = []
                break

            forecasts: dict[str, object] = {}
            best_model_type = None
            best_aicc = float("inf")

            if sarima_result is not None:
                if sarima_result.aicc < best_aicc:
                    best_aicc = sarima_result.aicc
                    best_model_type = "sarima"
                forecasts["sarima"] = {
                    "config": {
                        "order": sarima_result.config.order,
                        "seasonal_order": sarima_result.config.seasonal_order,
                    },
                    "aic": sarima_result.aic,
                    "aicc": sarima_result.aicc,
                    "bic": sarima_result.bic,
                    "ljung_box_pvalue": sarima_result.ljung_box_pvalue,
                    "params": sarima_result.params,
                    "forecast": sarima_result.forecast.tolist(),
                }

            if ets_result is not None:
                if ets_result.aicc < best_aicc:
                    best_aicc = ets_result.aicc
                    best_model_type = "ets"
                forecasts["ets"] = {
                    "seasonal": ets_result.seasonal,
                    "trend": ets_result.trend,
                    "seasonal_periods": ets_result.seasonal_periods,
                    "aic": ets_result.aic,
                    "aicc": ets_result.aicc,
                    "bic": ets_result.bic,
                    "ljung_box_pvalue": ets_result.ljung_box_pvalue,
                    "forecast": ets_result.forecast.tolist(),
                }

            if not forecasts:
                continue

            acf_values, pacf_values = compute_acf_pacf(seg_series.to_numpy(), nlags=24)
            forecast_index = _build_forecast_index(seg_series.index[-1], args.forecast_steps)

            segment_payload = {
                "segment_index": segment_index,
                "segment_start": segment.start.isoformat(),
                "segment_end": segment.end.isoformat(),
                "gap_filled": bool(segment.gap_filled),
                "max_gap_months": max_gap,
                "min_segment_months": min_observations,
                "best_model": best_model_type,
                "sarima": forecasts.get("sarima"),
                "ets": forecasts.get("ets"),
                "acf": acf_values.tolist(),
                "pacf": pacf_values.tolist(),
                "forecast_index": forecast_index,
            }
            segment_payloads.append(segment_payload)

            summary_rows.append(
                {
                    "node_id": node_id,
                    "segment_index": segment_index,
                    "segment_start": segment.start.isoformat(),
                    "segment_end": segment.end.isoformat(),
                    "gap_filled": bool(segment.gap_filled),
                    "max_gap_months": max_gap,
                    "min_segment_months": min_observations,
                    "best_model": best_model_type,
                    "sarima_aicc": forecasts.get("sarima", {}).get("aicc"),
                    "sarima_order": forecasts.get("sarima", {}).get("config", {}).get("order"),
                    "sarima_seasonal_order": forecasts.get("sarima", {}).get("config", {}).get("seasonal_order"),
                    "sarima_ljung_box_pvalue": forecasts.get("sarima", {}).get("ljung_box_pvalue"),
                    "ets_aicc": forecasts.get("ets", {}).get("aicc"),
                    "ets_trend": forecasts.get("ets", {}).get("trend"),
                    "ets_seasonal": forecasts.get("ets", {}).get("seasonal"),
                    "ets_ljung_box_pvalue": forecasts.get("ets", {}).get("ljung_box_pvalue"),
                    "observations": int(seg_series.dropna().size),
                }
            )

        if not segment_payloads:
            continue

        node_payload = {
            "node_id": node_id,
            "segments": segment_payloads,
        }
        node_path = nodes_dir / f"{node_id}.json"
        node_path.write_text(json.dumps(node_payload, indent=2, sort_keys=True), encoding="utf-8")

    if summary_rows:
        summary_path = output_dir / "time_series_summary.csv"
        pd.DataFrame(summary_rows).to_csv(summary_path, index=False)
    else:
        print("No nodes met the minimum observation threshold; no models generated.")


if __name__ == "__main__":  # pragma: no cover
    main()
